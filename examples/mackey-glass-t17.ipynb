{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Timeseries prediction of the Mackey-Glass Equation with ESNs \n",
    "\n",
    "## Introduction\n",
    "\n",
    "The Mackey-Glass system is essentially the differential equation, where we set the parameters to $\\alpha = 0.2$, $\\beta = 10$, $\\gamma = 0.1$ and the time delay $\\tau = 17$ in  order to have a mildly chaotic attractor. \n",
    "\n",
    "\\begin{align}\n",
    "\\label{eq:MackeyGlass}\n",
    "\\dot{y}(t) = \\alpha y(t-\\tau) / (1 + y(t - \\tau)^{\\beta}) - \\gamma y(t)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "from pyrcn.echo_state_network import ESNRegressor\n",
    "from pyrcn.extreme_learning_machine import ELMRegressor\n",
    "from pyrcn.linear_model import IncrementalRegression\n",
    "from pyrcn.model_selection import SequentialSearchCV\n",
    "from pyrcn.datasets import mackey_glass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and rescale it to a range of [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X, y = mackey_glass(n_timesteps=20000)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)).fit(X=X.reshape(-1, 1))\n",
    "X = scaler.transform(X=X.reshape(-1, 1))\n",
    "y = scaler.transform(y.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Train/Test lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainLen = 1900 # number of time steps during which we train the network\n",
    "testLen = 2000 # number of time steps during which we test/run the network\n",
    "\n",
    "X_train = X[:trainLen]\n",
    "y_train = y[:trainLen]\n",
    "X_test = X[trainLen:trainLen+testLen]\n",
    "y_test = y[trainLen:trainLen+testLen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fix, axs = plt.subplots()\n",
    "sns.lineplot(data=X_train.ravel(), ax=axs)\n",
    "sns.lineplot(data=y_train.ravel(), ax=axs)\n",
    "axs.set_xlim([0, 1900])\n",
    "axs.set_xlabel('n')\n",
    "axs.set_ylabel('u[n]')\n",
    "plt.legend([\"Input\", \"Target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Prediction using vanilla ESNs and ELMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize an ESNRegressor\n",
    "esn = ESNRegressor()  # IncrementalRegression()\n",
    "\n",
    "# initialize an ELMRegressor\n",
    "elm = ELMRegressor(regressor=Ridge())  # Ridge()\n",
    "\n",
    "# train a model\n",
    "esn.fit(X=X_train.reshape(-1, 1), y=y_train)\n",
    "elm.fit(X=X_train.reshape(-1, 1), y=y_train)\n",
    "\n",
    "# evaluate the models\n",
    "y_test_pred = esn.predict(X=X_test)\n",
    "print(mean_squared_error(y_test, y_test_pred))\n",
    "y_test_pred = elm.predict(X=X_test)\n",
    "print(mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter optimization ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Echo State Network sequential hyperparameter tuning\n",
    "initially_fixed_params = {'hidden_layer_size': 100,\n",
    "                          'input_activation': 'identity',\n",
    "                          'bias_scaling': 0.0,\n",
    "                          'reservoir_activation': 'tanh',\n",
    "                          'leakage': 1.0,\n",
    "                          'bi_directional': False,\n",
    "                          'k_rec': 10,\n",
    "                          'wash_out': 0,\n",
    "                          'continuation': False,\n",
    "                          'alpha': 1e-5,\n",
    "                          'random_state': 42,\n",
    "                          'requires_sequence': False}\n",
    "\n",
    "step1_esn_params = {'input_scaling': np.linspace(0.1, 5.0, 50),\n",
    "                    'spectral_radius': np.linspace(0.0, 1.5, 16)}\n",
    "step2_esn_params = {'leakage': np.linspace(0.1, 1.0, 10)}\n",
    "step3_esn_params = {'bias_scaling': np.linspace(0.0, 1.5, 16)}\n",
    "\n",
    "scorer = make_scorer(score_func=mean_squared_error, greater_is_better=False)\n",
    "\n",
    "kwargs = {'verbose': 5,\n",
    "          'scoring': scorer,\n",
    "          'n_jobs': -1,\n",
    "          'cv': TimeSeriesSplit()}\n",
    "\n",
    "esn = ESNRegressor(regressor=Ridge(), **initially_fixed_params)\n",
    "\n",
    "searches = [('step1', GridSearchCV, step1_esn_params, kwargs),\n",
    "            ('step2', GridSearchCV, step2_esn_params, kwargs),\n",
    "            ('step3', GridSearchCV, step3_esn_params, kwargs)]\n",
    "\n",
    "\n",
    "sequential_search_esn = SequentialSearchCV(esn, searches=searches).fit(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter optimization ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extreme Learning Machine sequential hyperparameter tuning\n",
    "initially_fixed_elm_params = {'hidden_layer_size': 100,\n",
    "                              'activation': 'tanh',\n",
    "                              'k_in': 1,\n",
    "                              'alpha': 1e-5,\n",
    "                              'random_state': 42 }\n",
    "\n",
    "step1_elm_params = {'input_scaling': np.linspace(0.1, 5.0, 50)}\n",
    "step2_elm_params = {'bias_scaling': np.linspace(0.0, 1.5, 16)}\n",
    "\n",
    "scorer = make_scorer(score_func=mean_squared_error, greater_is_better=False)\n",
    "\n",
    "kwargs = {'verbose': 5,\n",
    "          'scoring': scorer,\n",
    "          'n_jobs': -1,\n",
    "          'cv': TimeSeriesSplit()}\n",
    "\n",
    "elm = ELMRegressor(regressor=Ridge(), **initially_fixed_elm_params)\n",
    "\n",
    "searches = [('step1', GridSearchCV, step1_elm_params, kwargs),\n",
    "            ('step2', GridSearchCV, step2_elm_params, kwargs)]\n",
    "\n",
    "sequential_search_elm = SequentialSearchCV(elm, searches=searches).fit(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final prediction and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_search_esn.all_best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_search_elm.all_best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = sequential_search_esn.best_estimator_\n",
    "elm = sequential_search_elm.best_estimator_\n",
    "\n",
    "y_train_pred_esn = esn.predict(X=X_train)\n",
    "y_train_pred_elm = elm.predict(X=X_train)\n",
    "y_test_pred_esn = esn.predict(X=X_test)\n",
    "y_test_pred_elm = elm.predict(X=X_test)\n",
    "\n",
    "test_err_esn = mean_squared_error(y_true=y_test, y_pred=y_test_pred_esn)\n",
    "test_err_elm = mean_squared_error(y_true=y_test, y_pred=y_test_pred_elm)\n",
    "\n",
    "print(\"Test MSE ESN:\\t{0}\".format(test_err_esn))\n",
    "print(\"Test MSE ELM:\\t{0}\".format(test_err_elm))\n",
    "\n",
    "# Prediction of the test set.\n",
    "fix, axs = plt.subplots()\n",
    "sns.lineplot(data=y_test_pred_esn, ax=axs)\n",
    "sns.lineplot(data=y_test_pred_elm, ax=axs)\n",
    "axs.set_xlim([0, 1900])\n",
    "axs.set_xlabel('n')\n",
    "axs.set_ylabel('u[n]')\n",
    "plt.legend([\"ESN prediction\", \"ELM prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "sns.heatmap(data=esn.hidden_layer_state[:100, :].T, ax=axs[0], cbar=False)\n",
    "axs[0].set_xlabel(\"Time Step\")\n",
    "axs[0].set_ylabel(\"Neuron Index\")\n",
    "sns.heatmap(data=elm.hidden_layer_state[:100, :].T, ax=axs[1])\n",
    "axs[1].set_xlabel(\"Time Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
