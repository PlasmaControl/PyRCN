{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "module_path = os.path.dirname(cwd)  # target working directory\n",
    "\n",
    "sys.path = [item for item in sys.path if item != module_path]  # remove module_path from sys.path\n",
    "sys.path.append(module_path)  # add module_path to sys.path\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from scipy import sparse\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import make_scorer\n",
    "from pyrcn.metrics import mean_squared_error, accuracy_score\n",
    "from pyrcn.model_selection import SequentialSearchCV\n",
    "from pyrcn.util import FeatureExtractor\n",
    "from pyrcn.datasets import fetch_ptdb_tug_dataset\n",
    "from pyrcn.echo_state_network import ESNClassifier\n",
    "from pyrcn.base.blocks import PredefinedWeightsInputToNode, PredefinedWeightsNodeToNode\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "mpl.rc('font', **{'family': 'serif'})\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMIT corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = list(Path(r\"E:\\TIMIT\\train\").rglob(\"*.wav\"))\n",
    "test_sentences = list(Path(r\"E:\\TIMIT\\test\").rglob(\"*.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phn_label(phn, frame, hop_length, num_of_frame):\n",
    "    label = np.empty(num_of_frame, dtype='U5')\n",
    "    label_number = 0\n",
    "    idx = int(phn[0][0])\n",
    "    for i in range(num_of_frame):\n",
    "        if label_number >= len(phn):\n",
    "            label[i] = phn[-1][2]\n",
    "        elif int(phn[label_number][0]) <= idx < int(phn[label_number][1]):\n",
    "            label[i] = phn[label_number][2]\n",
    "        else:\n",
    "            if idx - int(phn[label_number][1]) <= frame / 2:\n",
    "                label[i] = phn[label_number][2]\n",
    "                label_number += 1\n",
    "            else:\n",
    "                label_number += 1\n",
    "                label[i] = phn[label_number][2]\n",
    "\n",
    "        idx += hop_length\n",
    "    return label\n",
    "\n",
    "\n",
    "def set_label_number(label):\n",
    "    phone_39set = {\"iy\": 0, \"ih\": 1, \"ix\": 1, \"eh\": 2, \"ae\": 3, \"ah\": 4, \"ax\": 4, \"ax-h\": 4, \"uw\": 5, \"ux\": 5, \"uh\": 6,\n",
    "                   \"aa\": 7, \"ao\": 7, \"ey\": 8, \"ay\": 9, \"oy\": 10, \"aw\": 11, \"ow\": 12, \"er\": 13, \"axr\": 13,\n",
    "                   \"l\": 14, \"el\": 14, \"r\": 15, \"w\": 16, \"y\": 17, \"m\": 18, \"em\": 18, \"n\": 19, \"en\": 19, \"nx\": 19,\n",
    "                   \"ng\": 20, \"eng\": 20, \"dx\": 21, \"jh\": 22, \"ch\": 23, \"z\": 24, \"s\": 25, \"sh\": 26, \"zh\": 26,\n",
    "                   \"hh\": 27, \"hv\": 27, \"v\": 28, \"f\": 29, \"dh\": 30, \"th\": 31, \"b\": 32, \"p\": 33, \"d\": 34, \"t\": 35,\n",
    "                   \"g\": 36, \"k\": 37, \"bcl\": 38, \"pcl\": 38, \"dcl\": 38, \"tcl\": 38, \"gcl\": 38, \"kcl\": 38, \"epi\": 38,\n",
    "                   \"pau\": 38, \"h\": 38, \"q\": 38}\n",
    "\n",
    "    label_idx = np.zeros(len(label))\n",
    "    for i in range(len(label)):\n",
    "        label_idx[i] = phone_39set[label[i]]\n",
    "\n",
    "    return label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3)\n",
    "for k, f in enumerate(shuffle(training_sentences, random_state=42)):\n",
    "    y, sr = librosa.core.load(str(f), sr=None, mono=False)\n",
    "    y = librosa.util.normalize(y)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=400, hop_length=160, \n",
    "                                         n_mels=40, center=False, window=\"hamming\")\n",
    "    mel = np.log(mel + 1e-5)\n",
    "    sns.heatmap(data=mel, ax=axs[np.unravel_index(k, (3, 3))])\n",
    "    if k >= 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3)\n",
    "for k, f in enumerate(shuffle(training_sentences, random_state=42)):\n",
    "    y, sr = librosa.core.load(str(f), sr=None, mono=False)\n",
    "    y = librosa.util.normalize(y)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=400, hop_length=160, \n",
    "                                         n_mels=40, center=False, window=\"hamming\")\n",
    "    mel = np.log(mel + 1e-5)\n",
    "    mel_delta = librosa.feature.delta(mel, width=5, order=1)\n",
    "    mel_deltadelta = librosa.feature.delta(mel, width=5, order=2)\n",
    "    sns.heatmap(data=np.vstack((mel, mel_delta, mel_deltadelta)), ax=axs[np.unravel_index(k, (3, 3))])\n",
    "    if k >= 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3)\n",
    "for k, f in enumerate(shuffle(training_sentences, random_state=42)):\n",
    "    y, sr = librosa.core.load(str(f), sr=None, mono=False)\n",
    "    y = librosa.util.normalize(y)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=400, hop_length=160, \n",
    "                                         n_mels=40, center=False, window=\"hamming\")\n",
    "    mel = np.log(mel + 1e-5)\n",
    "    mfcc=librosa.feature.mfcc(sr=sr, S=mel, n_mfcc=13, dct_type=2, n_fft=400,\n",
    "                              hop_length=160)\n",
    "    sns.heatmap(data=mfcc, ax=axs[np.unravel_index(k, (3, 3))])\n",
    "    if k >= 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3)\n",
    "for k, f in enumerate(shuffle(training_sentences, random_state=42)):\n",
    "    y, sr = librosa.core.load(str(f), sr=None, mono=False)\n",
    "    y = librosa.util.normalize(y)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=400, hop_length=160, \n",
    "                                         n_mels=40, center=False, window=\"hamming\")\n",
    "    mel = np.log(mel + 1e-5)\n",
    "    mfcc=librosa.feature.mfcc(sr=sr, S=mel, n_mfcc=13, dct_type=2, n_fft=400,\n",
    "                              hop_length=160)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc, width=5, order=1)\n",
    "    mfcc_deltadelta = librosa.feature.delta(mfcc, width=5, order=2)\n",
    "    sns.heatmap(data=np.vstack((mfcc, mfcc_delta, mfcc_deltadelta)), ax=axs[np.unravel_index(k, (3, 3))])\n",
    "    if k >= 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "from tqdm import tqdm\n",
    "for k, f in tqdm(enumerate(shuffle(training_sentences, random_state=42)[:100])):\n",
    "    if not \"sa\" in str(f):\n",
    "        y, sr = librosa.core.load(str(f), sr=None, mono=False)\n",
    "        y = librosa.util.normalize(y)\n",
    "        y = librosa.effects.preemphasis(y)\n",
    "        mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=400, hop_length=160, \n",
    "                                             n_mels=40, center=False, window=\"hamming\")\n",
    "        mel = np.log(mel + 1e-5)\n",
    "        mel_delta = librosa.feature.delta(mel, width=5, order=1)\n",
    "        mel_deltadelta = librosa.feature.delta(mel, width=5, order=2)\n",
    "        X_train.append(np.vstack((mel, mel_delta, mel_deltadelta)).T)\n",
    "        scaler.partial_fit(X_train[-1])\n",
    "        phn = np.loadtxt(str(f).replace(\".wav\", \".phn\"), dtype=str)\n",
    "        label = phn_label(phn=phn, frame=400, hop_length=160, num_of_frame=X_train[-1].shape[0])\n",
    "        label_idx = set_label_number(label)\n",
    "        y_train.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, f in tqdm(enumerate(shuffle(test_sentences, random_state=42)[:100])):\n",
    "    if not \"sa\" in str(f):\n",
    "        y, sr = librosa.core.load(str(f), sr=None, mono=False)\n",
    "        y = librosa.util.normalize(y)\n",
    "        y = librosa.effects.preemphasis(y)\n",
    "        mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=400, hop_length=160, \n",
    "                                             n_mels=40, center=False, window=\"hamming\")\n",
    "        mel = np.log(mel + 1e-5)\n",
    "        mel_delta = librosa.feature.delta(mel, width=5, order=1)\n",
    "        mel_deltadelta = librosa.feature.delta(mel, width=5, order=2)\n",
    "        X_test.append(np.vstack((mel, mel_delta, mel_deltadelta)).T)\n",
    "        phn = np.loadtxt(str(f).replace(\".wav\", \".phn\"), dtype=str)\n",
    "        label = phn_label(phn=phn, frame=400, hop_length=160, num_of_frame=X_test[-1].shape[0])\n",
    "        label_idx = set_label_number(label)\n",
    "        y_test.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train, dtype=object)\n",
    "X_test = np.asarray(X_test, dtype=object)\n",
    "y_train = np.asarray(y_train, dtype=object)\n",
    "y_test = np.asarray(y_test, dtype=object)\n",
    "for k, X in enumerate(X_train):\n",
    "    X_train[k] = scaler.transform(X)\n",
    "for k, X in enumerate(X_test):\n",
    "    X_test[k] = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_train[0].shape, y_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initially_fixed_params = {'hidden_layer_size': 50,\n",
    "                          'k_in': 10,\n",
    "                          'input_scaling': 0.4,\n",
    "                          'input_activation': 'identity',\n",
    "                          'bias_scaling': 0.0,\n",
    "                          'spectral_radius': 1.0,\n",
    "                          'leakage': 0.1,\n",
    "                          'k_rec': 10,\n",
    "                          'reservoir_activation': 'tanh',\n",
    "                          'bidirectional': False,\n",
    "                          'alpha': 1e-5,\n",
    "                          'random_state': 42,\n",
    "                          'requires_sequence': True}\n",
    "\n",
    "step1_esn_params = {'input_scaling': uniform(loc=1e-2, scale=1),\n",
    "                    'spectral_radius': uniform(loc=0, scale=2)}\n",
    "\n",
    "step2_esn_params = {'leakage': loguniform(1e-5, 1e0)}\n",
    "step3_esn_params = {'bias_scaling': np.linspace(0.0, 1.0, 11)}\n",
    "step4_esn_params = {'alpha': loguniform(1e-5, 1e1)}\n",
    "scoring = {\"MSE\": make_scorer(mean_squared_error, greater_is_better=False, needs_proba=True), \n",
    "           \"Acc\": make_scorer(accuracy_score)}\n",
    "\n",
    "kwargs_step1 = {'n_iter': 200, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': scoring, 'refit': \"MSE\"}\n",
    "kwargs_step2 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': scoring, 'refit': \"MSE\"}\n",
    "kwargs_step3 = {'verbose': 1, 'n_jobs': -1, 'scoring': scoring, 'refit': \"MSE\"}\n",
    "kwargs_step4 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': scoring, 'refit': \"MSE\"}\n",
    "\n",
    "searches = [('step1', RandomizedSearchCV, step1_esn_params, kwargs_step1),\n",
    "            ('step2', RandomizedSearchCV, step2_esn_params, kwargs_step2),\n",
    "            ('step3', GridSearchCV, step3_esn_params, kwargs_step3),\n",
    "            ('step4', RandomizedSearchCV, step3_esn_params, kwargs_step4)]\n",
    "\n",
    "base_esn = ESNClassifier(**initially_fixed_params)\n",
    "\n",
    "try:\n",
    "    sequential_search = load(\"../../sequential_search_speech_timit_random.joblib\")\n",
    "except FileNotFoundError:\n",
    "    sequential_search = SequentialSearchCV(base_esn, searches=searches).fit(X_train, y_train)\n",
    "    dump(sequential_search, \"../sequential_search_speech_timit_random.joblib\")\n",
    "print(sequential_search.all_best_params_, sequential_search.all_best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step1\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "ax = sns.scatterplot(x=\"param_spectral_radius\", y=\"param_input_scaling\", hue=\"mean_test_score\", palette='viridis', data=df)\n",
    "plt.xlabel(\"Spectral Radius\")\n",
    "plt.ylabel(\"Input Scaling\")\n",
    "\n",
    "norm = plt.Normalize(0.55, 0.65)\n",
    "# sm = plt.cm.ScalarMappable(cmap=\"viridis\")\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "sm.set_array([])\n",
    "plt.xlim((0, 2.01))\n",
    "plt.ylim((0, 1.03))\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "ax.get_legend().remove()\n",
    "ax.figure.colorbar(sm, label='CER')\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax.yaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "# plt.savefig('optimize_is_sr_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step2\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_leakage\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Leakage\")\n",
    "plt.ylabel(\"CER\")\n",
    "# plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.4f'))\n",
    "# plt.savefig('optimize_leakage_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step3\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_bias_scaling\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Bias Scaling\")\n",
    "plt.ylabel(\"CER\")\n",
    "plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.5f'))\n",
    "# plt.savefig('optimize_bias_scaling_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step4\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_alpha\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"CER\")\n",
    "plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.5f'))\n",
    "plt.grid()\n",
    "# plt.savefig('optimize_bias_scaling_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "\n",
    "# TODO: Plot the input weights\n",
    "sns.heatmap(sequential_search.best_estimator_.node_to_node.recurrent_weights.todense(), square=True, ax=axs)\n",
    "fig.set_size_inches(3.2, 2.5)\n",
    "# plt.savefig('recurrent_weights_random_timit.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "\n",
    "# TODO: Plot the input weights\n",
    "sns.heatmap(sequential_search.best_estimator_.input_to_node.input_weights.todense().T, ax=axs)\n",
    "fig.set_size_inches(3.2, 2.5)\n",
    "# plt.savefig('input_weights_random_timit.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means training and transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transition_matrix(transitions):\n",
    "    n = 1+ max(transitions) #number of states\n",
    "\n",
    "    M = np.zeros(shape=(n,n))\n",
    "\n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        M[i][j] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "    return M\n",
    "\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=50, n_init=200, reassignment_ratio=0, max_no_improvement=50, init='k-means++', verbose=2, random_state=0)\n",
    "kmeans.fit(X=np.concatenate(np.concatenate((X_train, X_test))))\n",
    "w_in = np.divide(kmeans.cluster_centers_, np.linalg.norm(kmeans.cluster_centers_, axis=1)[:, None])\n",
    "input_to_node = PredefinedWeightsInputToNode(predefined_input_weights=w_in.T)\n",
    "w_rec = transition_matrix(kmeans.labels_)\n",
    "node_to_node = PredefinedWeightsNodeToNode(predefined_recurrent_weights=w_rec)\n",
    "node_to_node_eig = PredefinedWeightsNodeToNode(predefined_recurrent_weights=w_rec / np.max(np.abs(np.linalg.eigvals(w_rec))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KM-ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initially_fixed_params = {'hidden_layer_size': 50,\n",
    "                          'k_in': 10,\n",
    "                          'input_scaling': 0.4,\n",
    "                          'input_activation': 'identity',\n",
    "                          'bias_scaling': 0.0,\n",
    "                          'spectral_radius': 1.0,\n",
    "                          'leakage': 0.1,\n",
    "                          'k_rec': 10,\n",
    "                          'reservoir_activation': 'tanh',\n",
    "                          'bi_directional': False,\n",
    "                          'wash_out': 0,\n",
    "                          'continuation': False,\n",
    "                          'alpha': 1e-5,\n",
    "                          'random_state': 42}\n",
    "\n",
    "step1_esn_params = {'input_scaling': uniform(loc=1e-2, scale=1),\n",
    "                    'spectral_radius': uniform(loc=0, scale=2)}\n",
    "\n",
    "step2_esn_params = {'leakage': loguniform(1e-5, 1e0)}\n",
    "step3_esn_params = {'bias_scaling': np.linspace(0.0, 1.0, 11)}\n",
    "step4_esn_params = {'alpha': loguniform(1e-5, 1e1)}\n",
    "scoring = {\"MSE\": make_scorer(mean_squared_error, greater_is_better=False, needs_proba=True), \n",
    "           \"Acc\": make_scorer(accuracy_score)}\n",
    "\n",
    "kwargs_step1 = {'n_iter': 200, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': scoring, 'refit': 'MSE'}\n",
    "kwargs_step2 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': scoring, 'refit': 'MSE'}\n",
    "kwargs_step3 = {'verbose': 1, 'n_jobs': -1, 'scoring': scoring, 'refit': 'MSE'}\n",
    "kwargs_step4 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': scoring, 'refit': 'MSE'}\n",
    "\n",
    "searches = [('step1', RandomizedSearchCV, step1_esn_params, kwargs_step1),\n",
    "            ('step2', RandomizedSearchCV, step2_esn_params, kwargs_step2),\n",
    "            ('step3', GridSearchCV, step3_esn_params, kwargs_step3),\n",
    "            ('step4', RandomizedSearchCV, step3_esn_params, kwargs_step4)]\n",
    "\n",
    "base_esn = SeqToSeqESNClassifier(input_to_node=input_to_node).set_params(**initially_fixed_params)\n",
    "\n",
    "try:\n",
    "    sequential_search = load(\"../sequential_search_speech_timit_kmeans.joblib\")\n",
    "except FileNotFoundError:\n",
    "    sequential_search = SequentialSearchCV(base_esn, searches=searches).fit(X_train, y_train)\n",
    "    dump(sequential_search, \"../sequential_search_speech_timit_kmeans.joblib\")\n",
    "print(sequential_search.all_best_params_, sequential_search.all_best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step1\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "ax = sns.scatterplot(x=\"param_spectral_radius\", y=\"param_input_scaling\", hue=\"mean_test_score\", palette='viridis', data=df)\n",
    "plt.xlabel(\"Spectral Radius\")\n",
    "plt.ylabel(\"Input Scaling\")\n",
    "\n",
    "norm = plt.Normalize(0.55, 0.65)\n",
    "# sm = plt.cm.ScalarMappable(cmap=\"viridis\")\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "sm.set_array([])\n",
    "plt.xlim((0, 2.01))\n",
    "plt.ylim((0, 1.03))\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "ax.get_legend().remove()\n",
    "ax.figure.colorbar(sm, label='CER')\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax.yaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "# plt.savefig('optimize_is_sr_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step2\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_leakage\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Leakage\")\n",
    "plt.ylabel(\"CER\")\n",
    "# plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.4f'))\n",
    "# plt.savefig('optimize_leakage_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step3\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_bias_scaling\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Bias Scaling\")\n",
    "plt.ylabel(\"CER\")\n",
    "plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.5f'))\n",
    "# plt.savefig('optimize_bias_scaling_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step4\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_alpha\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"CER\")\n",
    "plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.5f'))\n",
    "# plt.savefig('optimize_bias_scaling_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "\n",
    "# TODO: Plot the input weights\n",
    "sns.heatmap(sequential_search.best_estimator_.input_to_node.input_weights.T, ax=axs)\n",
    "fig.set_size_inches(3.2, 2.5)\n",
    "# plt.savefig('input_weights_timit_kmeans.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KM-ESN with transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initially_fixed_params = {'hidden_layer_size': 50,\n",
    "                          'k_in': 10,\n",
    "                          'input_scaling': 0.4,\n",
    "                          'input_activation': 'identity',\n",
    "                          'bias_scaling': 0.0,\n",
    "                          'spectral_radius': 1.0,\n",
    "                          'leakage': 0.1,\n",
    "                          'k_rec': 10,\n",
    "                          'reservoir_activation': 'tanh',\n",
    "                          'bi_directional': False,\n",
    "                          'wash_out': 0,\n",
    "                          'continuation': False,\n",
    "                          'alpha': 1e-5,\n",
    "                          'random_state': 42}\n",
    "\n",
    "step1_esn_params = {'input_scaling': uniform(loc=1e-2, scale=1),\n",
    "                    'spectral_radius': uniform(loc=0, scale=2)}\n",
    "\n",
    "step2_esn_params = {'leakage': loguniform(1e-5, 1e0)}\n",
    "step3_esn_params = {'bias_scaling': np.linspace(0.0, 1.0, 11)}\n",
    "step4_esn_params = {'alpha': loguniform(1e-5, 1e1)}\n",
    "\n",
    "kwargs_step1 = {'n_iter': 200, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "kwargs_step2 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "kwargs_step3 = {'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "kwargs_step4 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "\n",
    "searches = [('step1', RandomizedSearchCV, step1_esn_params, kwargs_step1),\n",
    "            ('step2', RandomizedSearchCV, step2_esn_params, kwargs_step2),\n",
    "            ('step3', GridSearchCV, step3_esn_params, kwargs_step3),\n",
    "            ('step4', RandomizedSearchCV, step3_esn_params, kwargs_step4)]\n",
    "\n",
    "base_esn = SeqToSeqESNClassifier(input_to_node=input_to_node,\n",
    "                                 node_to_node=node_to_node).set_params(**initially_fixed_params)\n",
    "\n",
    "try:\n",
    "    sequential_search = load(\"../sequential_search_speech_timit_kmeans_rec.joblib\")\n",
    "except FileNotFoundError:\n",
    "    sequential_search = SequentialSearchCV(base_esn, searches=searches).fit(X_train, y_train)\n",
    "    dump(sequential_search, \"../sequential_search_speech_timit_kmeans_rec.joblib\")\n",
    "print(sequential_search.all_best_params_, sequential_search.all_best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step1\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "ax = sns.scatterplot(x=\"param_spectral_radius\", y=\"param_input_scaling\", hue=\"mean_test_score\", palette='viridis', data=df)\n",
    "plt.xlabel(\"Spectral Radius\")\n",
    "plt.ylabel(\"Input Scaling\")\n",
    "\n",
    "norm = plt.Normalize(0.55, 0.65)\n",
    "# sm = plt.cm.ScalarMappable(cmap=\"viridis\")\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "sm.set_array([])\n",
    "plt.xlim((0, 2.01))\n",
    "plt.ylim((0, 1.03))\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "ax.get_legend().remove()\n",
    "ax.figure.colorbar(sm, label='CER')\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax.yaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "# plt.savefig('optimize_is_sr_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step2\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_leakage\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Leakage\")\n",
    "plt.ylabel(\"CER\")\n",
    "# plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.4f'))\n",
    "# plt.savefig('optimize_leakage_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step3\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_bias_scaling\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Bias Scaling\")\n",
    "plt.ylabel(\"CER\")\n",
    "plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.5f'))\n",
    "# plt.savefig('optimize_bias_scaling_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step4\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_alpha\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"CER\")\n",
    "plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.5f'))\n",
    "# plt.savefig('optimize_bias_scaling_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "\n",
    "# TODO: Plot the input weights\n",
    "sns.heatmap(sequential_search.best_estimator_.node_to_node.recurrent_weights, square=True, ax=axs)\n",
    "fig.set_size_inches(3.2, 1.25)\n",
    "# plt.savefig('recurrent_weights_timit_transition.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KM-ESN with normalized transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initially_fixed_params = {'hidden_layer_size': 50,\n",
    "                          'k_in': 10,\n",
    "                          'input_scaling': 0.4,\n",
    "                          'input_activation': 'identity',\n",
    "                          'bias_scaling': 0.0,\n",
    "                          'spectral_radius': 1.0,\n",
    "                          'leakage': 0.1,\n",
    "                          'k_rec': 10,\n",
    "                          'reservoir_activation': 'tanh',\n",
    "                          'bi_directional': False,\n",
    "                          'wash_out': 0,\n",
    "                          'continuation': False,\n",
    "                          'alpha': 1e-5,\n",
    "                          'random_state': 42}\n",
    "\n",
    "step1_esn_params = {'input_scaling': uniform(loc=1e-2, scale=1),\n",
    "                    'spectral_radius': uniform(loc=0, scale=2)}\n",
    "\n",
    "step2_esn_params = {'leakage': loguniform(1e-5, 1e0)}\n",
    "step3_esn_params = {'bias_scaling': np.linspace(0.0, 1.0, 11)}\n",
    "step4_esn_params = {'alpha': loguniform(1e-5, 1e1)}\n",
    "\n",
    "kwargs_step1 = {'n_iter': 200, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "kwargs_step2 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "kwargs_step3 = {'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "kwargs_step4 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "\n",
    "searches = [('step1', RandomizedSearchCV, step1_esn_params, kwargs_step1),\n",
    "            ('step2', RandomizedSearchCV, step2_esn_params, kwargs_step2),\n",
    "            ('step3', GridSearchCV, step3_esn_params, kwargs_step3),\n",
    "            ('step4', RandomizedSearchCV, step3_esn_params, kwargs_step4)]\n",
    "\n",
    "base_esn = SeqToSeqESNClassifier(input_to_node=input_to_node,\n",
    "                                 node_to_node=node_to_node).set_params(**initially_fixed_params)\n",
    "\n",
    "try:\n",
    "    sequential_search = load(\"../sequential_search_speech_timit_kmeans_rec_rho.joblib\")\n",
    "except FileNotFoundError:\n",
    "    sequential_search = SequentialSearchCV(base_esn, searches=searches).fit(X_train, y_train)\n",
    "    dump(sequential_search, \"../sequential_search_speech_timit_kmeans_rec_rho.joblib\")\n",
    "print(sequential_search.all_best_params_, sequential_search.all_best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step1\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "ax = sns.scatterplot(x=\"param_spectral_radius\", y=\"param_input_scaling\", hue=\"mean_test_score\", palette='viridis', data=df)\n",
    "plt.xlabel(\"Spectral Radius\")\n",
    "plt.ylabel(\"Input Scaling\")\n",
    "\n",
    "norm = plt.Normalize(0.55, 0.65)\n",
    "# sm = plt.cm.ScalarMappable(cmap=\"viridis\")\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "sm.set_array([])\n",
    "plt.xlim((0, 2.01))\n",
    "plt.ylim((0, 1.03))\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "ax.get_legend().remove()\n",
    "ax.figure.colorbar(sm, label='CER')\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax.yaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "# plt.savefig('optimize_is_sr_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step2\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_leakage\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Leakage\")\n",
    "plt.ylabel(\"CER\")\n",
    "# plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.4f'))\n",
    "# plt.savefig('optimize_leakage_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step3\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_bias_scaling\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Bias Scaling\")\n",
    "plt.ylabel(\"CER\")\n",
    "plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.5f'))\n",
    "# plt.savefig('optimize_bias_scaling_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequential_search.all_cv_results_[\"step4\"])\n",
    "df[\"mean_test_score\"] = 1 - df[\"mean_test_score\"]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2, 1.25)\n",
    "ax = sns.lineplot(data=df, x=\"param_alpha\", y=\"mean_test_score\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"CER\")\n",
    "plt.xlim((0, 1))\n",
    "tick_locator = ticker.MaxNLocator(5)\n",
    "ax.xaxis.set_major_locator(tick_locator)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.5f'))\n",
    "# plt.savefig('optimize_bias_scaling_50.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "\n",
    "# TODO: Plot the input weights\n",
    "sns.heatmap(sequential_search.best_estimator_.node_to_node.recurrent_weights, square=True, ax=axs)\n",
    "fig.set_size_inches(3.2, 1.25)\n",
    "# plt.savefig('recurrent_weights_timit_transition_rho.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer().fit(38 - np.concatenate(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_model = GaussianHMM(n_components=39, \n",
    "                               covariance_type=\"full\", \n",
    "                               transmat_prior=transition_matrix(38-np.concatenate(y_train).astype(int)),\n",
    "                               startprob_prior=np.unique(38-np.concatenate(y_train), return_counts=True)[1] / len(np.concatenate(y_train)),\n",
    "                               n_iter=100).fit(lb.transform(38-np.concatenate(y_train)), lengths=np.asarray([len(y) for y in y_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "\n",
    "# TODO: Plot the input weights\n",
    "sns.heatmap(transition_model.transmat_, square=True, ax=axs)\n",
    "# fig.set_size_inches(3.2, 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_model.decode(lb.transform(38-y_train[1])), 38-y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
