{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_{0}$ extraction using the Pitch Tracking Dataset from TU Graz (PTDBUG)\n",
    "\n",
    "At first, import packages to be used for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, zero_one_loss\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "# from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.manifold import TSNE\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from pyrcn.echo_state_network import ESNRegressor\n",
    "from pyrcn.base import InputToNode, PredefinedWeightsInputToNode, NodeToNode\n",
    "from pyrcn.linear_model import IncrementalRegression\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "#Options\n",
    "params = {'image.cmap' : 'jet',\n",
    "          'text.usetex' : False,\n",
    "          'font.size' : 11,\n",
    "          'axes.titlesize' : 24,\n",
    "          'axes.labelsize' : 20,\n",
    "          'lines.linewidth' : 3,\n",
    "          'lines.markersize' : 10,\n",
    "          'xtick.labelsize' : 16,\n",
    "          'ytick.labelsize' : 16,\n",
    "          }\n",
    "plt.rcParams.update(params) \n",
    "# plt.rcParams['pdf.fonttype'] = 42\n",
    "# plt.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['text.usetex'] = False\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print number of files that are included in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = np.loadtxt(r\"/projects/p_transcriber/SPEECH_DATA/SPEECH_DATAsplit/training.txt\", dtype=str)\n",
    "validation_files = np.loadtxt(r\"/projects/p_transcriber/SPEECH_DATA/SPEECH_DATAsplit/validation.txt\", dtype=str)\n",
    "test_files = np.loadtxt(r\"/projects/p_transcriber/SPEECH_DATA/SPEECH_DATAsplit/test.txt\", dtype=str)\n",
    "print(\"{0}\\t{1}\\t{2}\".format(len(training_files), len(validation_files), len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio signal and normalize it.\n",
    "print(training_files[0])\n",
    "x, sr = librosa.core.load(training_files[0], sr=None, mono=False)\n",
    "stft_frames = np.abs(librosa.stft(x, n_fft=2048, hop_length=int(0.01*sr), win_length=int(0.04*sr)))**2\n",
    "S = librosa.power_to_db(stft_frames, ref=np.max)\n",
    "X = S.T\n",
    "print(sr)\n",
    "print(X[:, 65].shape)\n",
    "# Define time axis in seconds\n",
    "t = np.arange(len(x)) / sr\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(t, x, color='gray')\n",
    "# plt.xlabel('Time (seconds)')\n",
    "# plt.ylabel('Amplitude')\n",
    "plt.ylim([-0.3, 0.3])\n",
    "plt.title(\"Speech signal\")\n",
    "plt.subplot(4, 1, 2)\n",
    "librosa.display.specshow(stft_frames, sr=sr, y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar()\n",
    "plt.subplot(4, 1, 3)\n",
    "librosa.display.specshow(S, sr=sr, y_axis='log', x_axis='time')\n",
    "plt.title('Log-Power spectrogram')\n",
    "plt.colorbar()\n",
    "plt.subplot(4, 1, 4)\n",
    "librosa.display.specshow(np.log(stft_frames + 1.0), sr=sr, y_axis='log', x_axis='time')\n",
    "plt.title('Log-Power spectrogram')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    x, sr = librosa.core.load(file_name, sr=None, mono=False)\n",
    "    stft_frames = np.abs(librosa.stft(x, n_fft=2048, hop_length=int(0.01*sr), win_length=int(0.04*sr)))**2\n",
    "    S = np.log(stft_frames + 1.0)\n",
    "    X = np.pad(S.T[:, :65], ((2, 2), (0, 0)), 'edge')\n",
    "    U = np.concatenate((X[:-4, :], X[1:-3, :], X[2:-2, :], X[3:-1, :], X[4:, :]), axis=1)\n",
    "    y = np.zeros(shape=(S.T.shape[0], 2))\n",
    "    txt_data = np.loadtxt(file_name.replace(\"MIC\", \"REF\").replace(\"mic\", \"ref\").replace(\".wav\", \".f0\"), usecols=(0, 1))\n",
    "    y[2:2+len(txt_data), :] = txt_data\n",
    "    return U, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio signal and normalize it.\n",
    "print(training_files[0])\n",
    "x, sr = librosa.core.load(training_files[0], sr=None, mono=False)\n",
    "stft_frames = np.abs(librosa.stft(x, n_fft=2048, hop_length=int(0.01*sr), win_length=int(0.04*sr)))**2\n",
    "S = librosa.power_to_db(stft_frames, ref=np.max)\n",
    "X, y = extract_features(training_files[0])\n",
    "print(sr)\n",
    "print(X.shape)\n",
    "# Define time axis in seconds\n",
    "t = np.arange(len(x)) / sr\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(t, x, color='gray')\n",
    "# plt.xlabel('Time (seconds)')\n",
    "# plt.ylabel('Amplitude')\n",
    "plt.ylim([-0.3, 0.3])\n",
    "plt.title(\"Speech signal\")\n",
    "plt.subplot(4, 1, 2)\n",
    "librosa.display.specshow(stft_frames, sr=sr, y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar()\n",
    "plt.subplot(4, 1, 3)\n",
    "librosa.display.specshow(S, sr=sr, y_axis='log', x_axis='time')\n",
    "plt.title('Log-Power spectrogram')\n",
    "plt.colorbar()\n",
    "plt.subplot(4, 1, 4)\n",
    "librosa.display.specshow(X.T, sr=sr, y_axis='log', x_axis='time')\n",
    "plt.title('Normalized Log-Power spectrogram')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define several error functions for $f_{0}$ extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpe(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Gross pitch error:\n",
    "    \n",
    "    All frames that are considered voiced by both pitch tracker and ground truth, \n",
    "    for which the relative pitch error is higher than a certain threshold (\\SI{20}{\\percent}).\n",
    "    \n",
    "    \"\"\"\n",
    "    idx = np.nonzero(y_true*y_pred)[0]\n",
    "    return np.mean(np.abs(y_true[idx] - y_pred[idx]) > 0.2 * y_true[idx])\n",
    "\n",
    "\n",
    "def vde(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Voicing Decision Error:\n",
    "    \n",
    "    Proportion of frames for which an incorrect voiced/unvoiced decision is made.\n",
    "    \n",
    "    \"\"\"\n",
    "    return zero_one_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def fpe(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fine Pitch Error:\n",
    "    \n",
    "    Standard deviation of the distribution of relative error values (in cents) from the frames\n",
    "    that do not have gross pitch errors\n",
    "    \"\"\"\n",
    "    idx_voiced = np.nonzero(y_true * y_pred)[0]\n",
    "    idx_correct = np.argwhere(np.abs(y_true - y_pred) <= 0.2 * y_true).ravel()\n",
    "    idx = np.intersect1d(idx_voiced, idx_correct)\n",
    "    if idx.size == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 100 * np.std(np.log2(y_pred[idx] / y_true[idx]))\n",
    "\n",
    "\n",
    "def ffe(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    $f_{0}$ Frame Error:\n",
    "    \n",
    "    Proportion of frames for which an error (either according to the GPE or the VDE criterion) is made.\n",
    "    FFE can be seen as a single measure for assessing the overall performance of a pitch tracker.\n",
    "    \"\"\"\n",
    "    idx_correct = np.argwhere(np.abs(y_true - y_pred) <= 0.2 * y_true).ravel()\n",
    "    return 1 - len(idx_correct) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an Echo State Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input_to_node = InputToNode(hidden_layer_size=500, activation='identity', k_in=10, input_scaling=0.1, bias_scaling=0.0, random_state=10)\n",
    "base_node_to_node = NodeToNode(hidden_layer_size=500, spectral_radius=0.6, leakage=1.0, bias_scaling=1.0, k_rec=90, random_state=10)\n",
    "base_reg = IncrementalRegression(alpha=1e-3)\n",
    "\n",
    "base_esn = ESNRegressor(input_to_node=base_input_to_node,\n",
    "                        node_to_node=base_nodes_to_node,\n",
    "                        regressor=base_reg, \n",
    "                        random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to load a pre-trained ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    esn = load(\"dataset/f0_extraction/models/sparse_esn_500.joblib\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Fitting ESN with features from the training set...\")\n",
    "    esn = base_esn\n",
    "    with tqdm(total=len(training_files)) as pbar:\n",
    "        for k, file_name in enumerate(training_files[:-1]):\n",
    "            X, y = extract_features(file_name)\n",
    "            esn.partial_fit(X=X, y=y, postpone_inverse=True)\n",
    "            pbar.update(1)\n",
    "        X, y = extract_features(training_files[-1])\n",
    "        esn.partial_fit(X=X, y=y, postpone_inverse=False)\n",
    "        pbar.update(1)\n",
    "    print(\"done!\")\n",
    "    dump(esn, \"sparse_esn_500.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute errors on the training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpe_training = [None] * len(training_files)\n",
    "vde_training = [None] * len(training_files)\n",
    "fpe_training = [None] * len(training_files)\n",
    "ffe_training = [None] * len(training_files)\n",
    "with tqdm(total=len(training_files)) as pbar:\n",
    "    for k, file_name in enumerate(training_files):\n",
    "        X, y = extract_features(file_name)\n",
    "        y_pred = esn.predict(X=X)\n",
    "        gpe_training[k] = gpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        vde_training[k] = vde(y_true=y[:, 1], y_pred=y_pred[:, 1] >= .5)\n",
    "        fpe_training[k] = fpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        ffe_training[k] = ffe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        pbar.update(1)\n",
    "\n",
    "gpe_validation = [None] * len(validation_files)\n",
    "vde_validation = [None] * len(validation_files)\n",
    "fpe_validation = [None] * len(validation_files)\n",
    "ffe_validation = [None] * len(validation_files)\n",
    "with tqdm(total=len(validation_files)) as pbar:\n",
    "    for k, file_name in enumerate(validation_files):\n",
    "        X, y = extract_features(file_name)\n",
    "        y_pred = esn.predict(X=X)\n",
    "        gpe_validation[k] = gpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        vde_validation[k] = vde(y_true=y[:, 1], y_pred=y_pred[:, 1] >= .5)\n",
    "        fpe_validation[k] = fpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        ffe_validation[k] = ffe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        pbar.update(1)\n",
    "\n",
    "gpe_test = [None] * len(test_files)\n",
    "vde_test = [None] * len(test_files)\n",
    "fpe_test = [None] * len(test_files)\n",
    "ffe_test = [None] * len(test_files)\n",
    "with tqdm(total=len(test_files)) as pbar:\n",
    "    for k, file_name in enumerate(test_files):\n",
    "        X, y = extract_features(file_name)\n",
    "        y_pred = esn.predict(X=X)\n",
    "        gpe_test[k] = gpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        vde_test[k] = vde(y_true=y[:, 1], y_pred=y_pred[:, 1] >= .5)\n",
    "        fpe_test[k] = fpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        ffe_test[k] = ffe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"Training: GPE\\t VDE\\t FPE\\t FFE\")\n",
    "print(\"Training: {0}\\t {1}\\t {2}\\t {3}\".format(np.mean(gpe_training), np.mean(vde_training), np.mean(fpe_training), np.mean(ffe_training) ))\n",
    "print(\"Validation: GPE\\t VDE\\t FPE\\t FFE\")\n",
    "print(\"Validation: {0}\\t {1}\\t {2}\\t {3}\".format(np.mean(gpe_validation), np.mean(vde_validation), np.mean(fpe_validation), np.mean(ffe_validation) ))\n",
    "print(\"Test: GPE\\t VDE\\t FPE\\t FFE\")\n",
    "print(\"Test: {0}\\t {1}\\t {2}\\t {3}\".format(np.mean(gpe_test), np.mean(vde_test), np.mean(fpe_test), np.mean(ffe_test) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the negative examples from training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(gpe_training), np.argmax(gpe_validation), np.argmax(gpe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the positive examples from training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(gpe_training), np.argmin(gpe_validation), np.argmin(gpe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize worst and best training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(training_files[323])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "X, y = extract_features(training_files[303])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize worst and best validation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(validation_files[33])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "X, y = extract_features(validation_files[243])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize worst and best test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(test_files[21])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "X, y = extract_features(test_files[368])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K$-Means initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "kmeans = MiniBatchKMeans(n_clusters=500, n_init=20, reassignment_ratio=0, max_no_improvement=50, init='k-means++', verbose=1, random_state=0)\n",
    "print(\"Fitting kmeans with features from the training set...\")\n",
    "X = [None] * len(training_files)\n",
    "y = [None] * len(training_files)\n",
    "with tqdm(total=len(training_files)) as pbar:\n",
    "    for k, file_name in enumerate(training_files):\n",
    "        X[k], y[k] = extract_features(file_name)\n",
    "        pbar.update(1)\n",
    "    kmeans.fit(X=np.vstack(X))\n",
    "print(\"done in {0}!\".format(time.time() - t1))\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an Echo State Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_input_to_nodes.hidden_layer_size <=500:\n",
    "    w_in = np.divide(kmeans.cluster_centers_, np.linalg.norm(kmeans.cluster_centers_, axis=1)[:, None])\n",
    "else:\n",
    "    w_in = np.pad(np.divide(kmeans.cluster_centers_, np.linalg.norm(kmeans.cluster_centers_, axis=1)[:, None]), ((0, base_input_to_nodes.hidden_layer_size - 500), (0, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "base_input_to_node = PredefinedWeightsInputToNode(predefined_input_weights=w_in.T, activation='identity', input_scaling=0.1)\n",
    "base_node_to_node = NodeToNode(hidden_layer_size=500, spectral_radius=0.1, leakage=1.0, bias_scaling=2.1, k_rec=10, random_state=10)\n",
    "base_reg = FastIncrementalRegression(alpha=1e-3)\n",
    "\n",
    "base_esn = ESNRegressor(input_to_node=base_input_to_node,\n",
    "                        node_to_node=base_node_to_node,\n",
    "                        regressor=base_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to load a pre-trained ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    esn = load(\"dataset/f0_extraction/models/kmeans_esn_500.joblib\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Fitting ESN with features from the training set...\")\n",
    "    esn = base_esn\n",
    "    with tqdm(total=len(training_files)) as pbar:\n",
    "        for k, file_name in enumerate(training_files[:-1]):\n",
    "            X, y = extract_features(file_name)\n",
    "            esn.partial_fit(X=X, y=y, postpone_inverse=True)\n",
    "            pbar.update(1)\n",
    "        X, y = extract_features(training_files[-1])\n",
    "        esn.partial_fit(X=X, y=y, postpone_inverse=False)\n",
    "        pbar.update(1)\n",
    "    print(\"done!\")\n",
    "    dump(esn, \"kmeans_esn_500.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute errors on the training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpe_training = [None] * len(training_files)\n",
    "vde_training = [None] * len(training_files)\n",
    "fpe_training = [None] * len(training_files)\n",
    "ffe_training = [None] * len(training_files)\n",
    "with tqdm(total=len(training_files)) as pbar:\n",
    "    for k, file_name in enumerate(training_files):\n",
    "        X, y = extract_features(file_name)\n",
    "        y_pred = esn.predict(X=X)\n",
    "        gpe_training[k] = gpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        vde_training[k] = vde(y_true=y[:, 1], y_pred=y_pred[:, 1] >= .5)\n",
    "        fpe_training[k] = fpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        ffe_training[k] = ffe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        pbar.update(1)\n",
    "\n",
    "gpe_validation = [None] * len(validation_files)\n",
    "vde_validation = [None] * len(validation_files)\n",
    "fpe_validation = [None] * len(validation_files)\n",
    "ffe_validation = [None] * len(validation_files)\n",
    "with tqdm(total=len(validation_files)) as pbar:\n",
    "    for k, file_name in enumerate(validation_files):\n",
    "        X, y = extract_features(file_name)\n",
    "        y_pred = esn.predict(X=X)\n",
    "        gpe_validation[k] = gpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        vde_validation[k] = vde(y_true=y[:, 1], y_pred=y_pred[:, 1] >= .5)\n",
    "        fpe_validation[k] = fpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        ffe_validation[k] = ffe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        pbar.update(1)\n",
    "\n",
    "gpe_test = [None] * len(test_files)\n",
    "vde_test = [None] * len(test_files)\n",
    "fpe_test = [None] * len(test_files)\n",
    "ffe_test = [None] * len(test_files)\n",
    "with tqdm(total=len(test_files)) as pbar:\n",
    "    for k, file_name in enumerate(test_files):\n",
    "        X, y = extract_features(file_name)\n",
    "        y_pred = esn.predict(X=X)\n",
    "        gpe_test[k] = gpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        vde_test[k] = vde(y_true=y[:, 1], y_pred=y_pred[:, 1] >= .5)\n",
    "        fpe_test[k] = fpe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        ffe_test[k] = ffe(y_true=y[:, 0]*y[:, 1], y_pred=y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"Training: GPE\\t VDE\\t FPE\\t FFE\")\n",
    "print(\"Training: {0}\\t {1}\\t {2}\\t {3}\".format(np.mean(gpe_training), np.mean(vde_training), np.mean(fpe_training), np.mean(ffe_training) ))\n",
    "print(\"Validation: GPE\\t VDE\\t FPE\\t FFE\")\n",
    "print(\"Validation: {0}\\t {1}\\t {2}\\t {3}\".format(np.mean(gpe_validation), np.mean(vde_validation), np.mean(fpe_validation), np.mean(ffe_validation) ))\n",
    "print(\"Test: GPE\\t VDE\\t FPE\\t FFE\")\n",
    "print(\"Test: {0}\\t {1}\\t {2}\\t {3}\".format(np.mean(gpe_test), np.mean(vde_test), np.mean(fpe_test), np.mean(ffe_test) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the negative examples from training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(gpe_training), np.argmax(gpe_validation), np.argmax(gpe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the positive examples from training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(gpe_training), np.argmin(gpe_validation), np.argmin(gpe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize worst and best training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(training_files[1547])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "X, y = extract_features(training_files[7])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize worst and best validation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(validation_files[277])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "X, y = extract_features(validation_files[499])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize worst and best test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(test_files[21])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))\n",
    "X, y = extract_features(test_files[276])\n",
    "y_pred = esn.predict(X=X)\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(y[:, 0])\n",
    "plt.plot(y_pred[:, 0]*(y_pred[:, 1] >= .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
