{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing hand-written digits\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook adapts the existing example of applying support vector classification from scikit-learn ([https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py)) to PyRCN to demonstrate, how PyRCN can be used to classify hand-written digits.\n",
    "\n",
    "The tutorial is based on numpy, scikit-learn and PyRCN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from pyrcn.model_selection import SequentialSearchCV\n",
    "from pyrcn.echo_state_network import SeqToLabelESNClassifier\n",
    "from pyrcn.metrics import accuracy_score\n",
    "from pyrcn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "The dataset is already part of scikit-learn and consists of 1797 8x8 images. \n",
    "\n",
    "We are using our dataloader that is derived from scikit-learns dataloader and returns arrays of 8x8 sequences and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True, as_sequence=True)\n",
    "print(\"Number of digits: {0}\".format(len(X)))\n",
    "print(\"Shape of digits {0}\".format(X[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset in training and test\n",
    "\n",
    "Afterwards, we split the dataset into training and test sets. We train the ESN using 80% of the digits and test it using the remaining images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "print(\"Number of digits in training set: {0}\".format(len(X_train)))\n",
    "print(\"Shape of digits in training set: {0}\".format(X_train[0].shape))\n",
    "print(\"Number of digits in test set: {0}\".format(len(X_test)))\n",
    "print(\"Shape of digits in test set: {0}\".format(X_test[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a ESN\n",
    "\n",
    "To develop an ESN model for digit recognition, we need to tune several hyper-parameters, e.g., input_scaling, spectral_radius, bias_scaling and leaky integration.\n",
    "\n",
    "We follow the way proposed in the introductory paper of PyRCN to optimize hyper-parameters sequentially.\n",
    "\n",
    "We define the search spaces for each step together with the type of search (a grid search in this context).\n",
    "\n",
    "At last, we initialize a SeqToLabelESNClassifier with the desired output strategy and with the initially fixed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initially_fixed_params = {'hidden_layer_size': 50,\n",
    "                          'input_activation': 'identity',\n",
    "                          'k_in': 5,\n",
    "                          'bias_scaling': 0.0,\n",
    "                          'reservoir_activation': 'tanh',\n",
    "                          'leakage': 1.0,\n",
    "                          'bi_directional': False,\n",
    "                          'k_rec': 10,\n",
    "                          'wash_out': 0,\n",
    "                          'continuation': False,\n",
    "                          'alpha': 1e-5,\n",
    "                          'random_state': 42}\n",
    "\n",
    "step1_esn_params = {'input_scaling': np.linspace(0.1, 1.0, 10),\n",
    "                    'spectral_radius': np.linspace(0.0, 1.5, 16)}\n",
    "\n",
    "step2_esn_params = {'leakage': np.linspace(0.1, 1.0, 10)}\n",
    "step3_esn_params = {'bias_scaling': np.linspace(0.0, 1.0, 11)}\n",
    "step4_esn_params = {'alpha': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1e0]}\n",
    "\n",
    "kwargs = {'verbose': 1, 'n_jobs': -1, 'scoring': make_scorer(accuracy_score)}\n",
    "\n",
    "# The searches are defined similarly to the steps of a sklearn.pipeline.Pipeline:\n",
    "searches = [('step1', GridSearchCV, step1_esn_params, kwargs),\n",
    "            ('step2', GridSearchCV, step2_esn_params, kwargs),\n",
    "            ('step3', GridSearchCV, step3_esn_params, kwargs),\n",
    "            ('step4', GridSearchCV, step4_esn_params, kwargs)]\n",
    "\n",
    "base_esn = SeqToLabelESNClassifier(output_strategy=\"last_state\", **initially_fixed_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "We provide a SequentialSearchCV that basically iterates through the list of searches that we have defined before. It can be combined with any model selection tool from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequential_search = SequentialSearchCV(base_esn, searches=searches).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the ESN with final hyper-parameters\n",
    "\n",
    "After the optimization, we extract the ESN with final hyper-parameters as the result of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_esn = sequential_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the ESN\n",
    "\n",
    "Finally, we increase the reservoir size and compare the impact of uni- and bidirectional ESNs. Notice that the ESN strongly benefit from both, increasing the reservoir size and from the bi-directional working mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_size': [50, 100, 200, 400, 500],\n",
    "              'bi_directional': [False, True]}\n",
    "\n",
    "print(\"CV results\\tFit time\\tInference time\\tAccuracy score\\tSize[Bytes]\")\n",
    "for params in ParameterGrid(param_grid):\n",
    "    esn_cv = cross_validate(clone(base_esn).set_params(**params), X=X_train, y=y_train, scoring=make_scorer(accuracy_score), n_jobs=-1)\n",
    "    t1 = time.time()\n",
    "    esn = clone(base_esn).set_params(**params).fit(X_train, y_train)\n",
    "    t_fit = time.time() - t1\n",
    "    mem_size = esn.__sizeof__()\n",
    "    t1 = time.time()\n",
    "    acc_score = accuracy_score(y_test, esn.predict(X_test))\n",
    "    t_inference = time.time() - t1\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\".format(esn_cv, t_fit, t_inference, acc_score, mem_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
