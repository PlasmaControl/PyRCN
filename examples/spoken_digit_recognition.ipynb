{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoken digit recognition using the Free Spoken Digit Dataset (FSDD)\n",
    "\n",
    "At first, import packages to be used for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, ConfusionMatrixDisplay, silhouette_score\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.manifold import TSNE\n",
    "from joblib import Parallel, delayed\n",
    "from pyrcn.echo_state_network import ESNClassifier\n",
    "from pyrcn.linear_model import FastIncrementalRegression, IncrementalRegression\n",
    "from pyrcn.base import InputToNode, PredefinedWeightsInputToNode, NodeToNode\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "#Options\n",
    "import scipy.stats\n",
    "plt.rc('image', cmap='RdBu')\n",
    "plt.rc('font', family='serif', serif='Times')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "\"\"\"\n",
    "params = {'image.cmap' : 'RdBu',\n",
    "          'text.usetex' : True,\n",
    "          'font.size' : 11,\n",
    "          'axes.titlesize' : 24,\n",
    "          'axes.labelsize' : 20,\n",
    "          'lines.linewidth' : 3,\n",
    "          'lines.markersize' : 10,\n",
    "          'xtick.labelsize' : 16,\n",
    "          'ytick.labelsize' : 16,\n",
    "          'text.latex.unicode': True,\n",
    "          }\n",
    "plt.rcParams.update(params) \n",
    "# plt.rcParams['pdf.fonttype'] = 42\n",
    "# plt.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import ticker\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print number of files that are included in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(r\"E:\\free-spoken-digit-dataset\\recordings\\*.wav\")\n",
    "print(len(all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the audio signal and normalize it.\n",
    "basename = os.path.basename(all_files[0]).split('.')[0]\n",
    "x, sr = librosa.core.load(all_files[0], sr=None, mono=False)\n",
    "# x /= np.max(np.abs(x))\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr, hop_length=int(0.01*sr), n_fft=256, htk=True, n_mels=100, n_mfcc=13)\n",
    "# X = np.vstack((mfcc, mfcc_delta, mfcc_delta2))\n",
    "X = mfcc.T\n",
    "label = int(basename.split('_')[0])\n",
    "# Define time axis in seconds\n",
    "t = np.arange(len(x)) / sr\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, x, color='gray')\n",
    "# plt.xlabel('Time (seconds)')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.xlim([t[0], t[-1]])\n",
    "plt.ylim([-0.4, 0.4])\n",
    "plt.title(\"Speech signal\")\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(mfcc)\n",
    "plt.title('MFCC')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features and labels from all signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "time_signals_train = []\n",
    "time_signals_test = []\n",
    "f_name_train = []\n",
    "f_name_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "print(\"extracting features...\")\n",
    "with tqdm(total=len(all_files)) as pbar:\n",
    "    for k, f in enumerate(all_files):\n",
    "        basename = os.path.basename(f).split('.')[0]\n",
    "        # Get label (0-9) of recording.\n",
    "        label = int(basename.split('_')[0])\n",
    "        idx = int(basename.split('_')[2])\n",
    "        # Load the audio signal and normalize it.\n",
    "        x, sr = librosa.core.load(f, sr=None, mono=False)\n",
    "        # x /= np.max(np.abs(x))\n",
    "        mfcc = librosa.feature.mfcc(y=x, sr=sr, hop_length=int(0.01*sr), n_fft=256, htk=True, n_mels=100, n_mfcc=13)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        if idx <= 4:\n",
    "            f_name_test.append(f)\n",
    "            time_signals_test.append(x)\n",
    "            X_test.append(mfcc.T)\n",
    "            y_test.append(label)\n",
    "        else:\n",
    "            f_name_train.append(f)\n",
    "            time_signals_train.append(x)\n",
    "            X_train.append(mfcc.T)\n",
    "            y_train.append(label)\n",
    "        pbar.update(1)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_signals_train, time_signals_val, _, _ = train_test_split(time_signals_train, y_train, test_size=0.1, random_state=1, stratify=y_train)\n",
    "f_name_train, f_name_val_val, _, _ = train_test_split(f_name_train, y_train, test_size=0.1, random_state=1, stratify=y_train)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate training and test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(y_train), X_train[0].shape, y_train[0])\n",
    "print(len(X_val), len(y_val), X_val[0].shape, y_val[0])\n",
    "print(len(X_test), len(y_test), X_test[0].shape, y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize all features using the StandardScaler from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X=np.vstack(X_train))\n",
    "X_train_scaled = [scaler.transform(X) for X in X_train]\n",
    "X_val_scaled = [scaler.transform(X) for X in X_val]\n",
    "X_test_scaled = [scaler.transform(X) for X in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio signal and normalize it.\n",
    "basename = os.path.basename(all_files[0]).split('.')[0]\n",
    "x, sr = librosa.core.load(all_files[0], sr=None, mono=False)\n",
    "# x /= np.max(np.abs(x))\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr, hop_length=int(0.01*sr), n_fft=256, htk=True, n_mels=100, n_mfcc=13)\n",
    "X = mfcc.T\n",
    "label = int(basename.split('_')[0])\n",
    "# Define time axis in seconds\n",
    "t = np.arange(len(x)) / sr\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t, x, color='gray')\n",
    "# plt.xlabel('Time (seconds)')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.xlim([t[0], t[-1]])\n",
    "# plt.ylim([-0.4, 0.4])\n",
    "plt.title(\"Speech signal\")\n",
    "plt.subplot(3, 1, 2)\n",
    "librosa.display.specshow(mfcc)\n",
    "plt.title('MFCC')\n",
    "plt.colorbar()\n",
    "plt.subplot(3, 1, 3)\n",
    "librosa.display.specshow(X_train_scaled[0].T, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rs in range(20):\n",
    "    base_input_to_node = InputToNode(hidden_layer_size=100, activation='identity', k_in=10, input_scaling=0.4, bias_scaling=0.0, random_state=rs)\n",
    "    base_node_to_node = NodeToNode(hidden_layer_size=100, spectral_radius=1.0, leakage=0.1, bias_scaling=0.0, k_rec=10, random_state=10)\n",
    "\n",
    "    base_esn = ESNClassifier(input_to_node=base_input_to_node,\n",
    "                             node_to_node=base_node_to_node,\n",
    "                             regressor=FastIncrementalRegression(alpha=1e-3),\n",
    "                             random_state=rs)\n",
    "    print(\"Train the ESN model...\")\n",
    "    esn = clone(base_esn)\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled[:-1], y_train + y_val[:-1]):\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        esn.partial_fit(X=X, y=y, classes=np.arange(10), postpone_inverse=True)\n",
    "    X = X_val[-1]\n",
    "    y = np.repeat(y_val[-1], repeats=X.shape[0], axis=0)\n",
    "    esn.partial_fit(X=X, y=y, postpone_inverse=False)\n",
    "    print(\"... done!\")\n",
    "    Y_true_train = []\n",
    "    Y_pred_train = []\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled, y_train + y_val):\n",
    "        Y_true_train.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_train.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        # mse_train.append(mean_squared_error(y, y_pred))\n",
    "    print(\"Classification training report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_train, Y_pred_train, digits=10)))\n",
    "    # print(\"MSE training: %f\\n\" % (np.mean(mse_train)))\n",
    "    \n",
    "    Y_true_test = []\n",
    "    Y_pred_test = []\n",
    "    mse_test = []\n",
    "    for X, y in zip(X_test_scaled, y_test):\n",
    "        Y_true_test.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_test.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        # mse_test.append(mean_squared_error(y, y_pred))\n",
    "    print(\"Classification test report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_test, Y_pred_test, digits=10)))\n",
    "    # print(\"MSE test: %f\\n\" % (np.mean(mse_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an Echo State Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input_to_node = InputToNode(hidden_layer_size=100, activation='identity', k_in=10, input_scaling=0.4, bias_scaling=0.0, random_state=10)\n",
    "base_node_to_node = NodeToNode(hidden_layer_size=100, spectral_radius=1.0, leakage=0.1, bias_scaling=0.0, k_rec=10, random_state=10)\n",
    "\n",
    "base_esn = ESNClassifier(input_to_node=base_input_to_node,\n",
    "                         node_to_node=base_node_to_node,\n",
    "                         regressor=FastIncrementalRegression(alpha=1e-3),\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the base_esn and fit it on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "esn = clone(base_esn)\n",
    "print(\"Train the ESN model...\")\n",
    "with tqdm(total=len(X_train_scaled) + len(X_val_scaled)) as pbar:\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled[:-1], y_train + y_val[:-1]):\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        esn.partial_fit(X=X, y=y, classes=np.arange(10), postpone_inverse=True)\n",
    "        pbar.update(1)\n",
    "    X = X_val[-1]\n",
    "    y = np.repeat(y_val[-1], repeats=X.shape[0], axis=0)\n",
    "    esn.partial_fit(X=X, y=y, postpone_inverse=False)\n",
    "    pbar.update(1)\n",
    "print(\"... done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_true_train = []\n",
    "Y_pred_train = []\n",
    "with tqdm(total=len(X_train_scaled) + len(X_val_scaled)) as pbar:\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled, y_train + y_val):\n",
    "        Y_true_train.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_train.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        pbar.update(1)\n",
    "cm = confusion_matrix(Y_true_train, Y_pred_train)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).plot()\n",
    "print(\"Classification training report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_train, Y_pred_train, digits=10)))\n",
    "plt.show()\n",
    "\n",
    "Y_true_test = []\n",
    "Y_pred_test = []\n",
    "with tqdm(total=len(X_test_scaled)) as pbar:\n",
    "    for X, y in zip(X_test_scaled, y_test):\n",
    "        Y_true_test.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_test.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        pbar.update(1)\n",
    "cm = confusion_matrix(Y_true_test, Y_pred_test)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).plot()\n",
    "print(\"Classification test report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_test, Y_pred_test, digits=10)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of time signals from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=.15, bottom=.16, right=.99, top=.97)\n",
    "ax1 = plt.subplot(111)\n",
    "im = ax1.imshow(X_train_scaled[361].T,vmin=np.min(X_train_scaled[361]), vmax=np.max(X_train_scaled[361]))\n",
    "\n",
    "plt.xlim([0,X_train_scaled[361].shape[0]])\n",
    "plt.ylim([0, X_train_scaled[361].shape[1] - 1])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{u}[n]$')\n",
    "plt.grid()\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "ax2 = divider.append_axes(\"top\", size=\"100%\", pad=0.7)\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=0.2)\n",
    "cb = plt.colorbar( im, ax=ax1, cax=cax )\n",
    "\n",
    "t = np.arange(len(time_signals_train[361])) / sr\n",
    "#ax2 = plt.subplot( gs[-1,:] )  # , sharex=ax1\n",
    "ax2.plot(t, time_signals_train[361], 'dimgrey')\n",
    "ax2.set_xlim(t[0], t[-1])\n",
    "ax2.set_ylim(-0.4, 0.4)\n",
    "ax2.set_xlabel(r'$t$')\n",
    "ax2.set_ylabel(r'$y(t)$')\n",
    "ax2.grid(True)\n",
    "\n",
    "# fig.tight_layout()\n",
    "width = 3.487\n",
    "height =3 * width / 1.618\n",
    "fig.set_size_inches(width, height)\n",
    "plt.savefig('time_signal_and_features_train.pdf', bbox_inches = 'tight', pad_inches = 0)\n",
    "# np.savetxt(X=np.vstack((t, time_signals_train[1])).T, fname=\"time_signal_train.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of features from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=.15, bottom=.16, right=.99, top=.97)\n",
    "ax = plt.gca()\n",
    "im = plt.imshow(X_train_scaled[361].T,vmin=np.min(X_train_scaled[361]), vmax=np.max(X_train_scaled[361]))\n",
    "plt.xlim([0,X_train_scaled[361].shape[0]])\n",
    "plt.ylim([0, X_train_scaled[361].shape[1] - 1])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{u}[n]$')\n",
    "# plt.colorbar(im)\n",
    "plt.grid()\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=0.2)\n",
    "\n",
    "plt.colorbar(im, cax=cax)\n",
    "fig.set_size_inches(width, height)\n",
    "plt.savefig('features_train.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations of features from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=.15, bottom=.16, right=.99, top=.97)\n",
    "ax = plt.gca()\n",
    "im = plt.imshow(X_test_scaled[0].T,vmin=np.min(X_test_scaled[0]), vmax=np.max(X_test_scaled[0]))\n",
    "plt.xlim([0, X_test[0].shape[0]])\n",
    "plt.ylim([0, X_test[0].shape[1] - 1])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{u}[n]$')\n",
    "# plt.colorbar(im)\n",
    "plt.grid()\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=0.2)\n",
    "\n",
    "plt.colorbar(im, cax=cax)\n",
    "fig.set_size_inches(width, height)\n",
    "plt.savefig('features_test.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of a reservoir state from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = esn.predict(X=X_train_scaled[361])\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=.15, bottom=.16, right=.99, top=.97)\n",
    "ax = plt.gca()\n",
    "rng = np.random.default_rng(12345)\n",
    "idx = rng.choice(100, 50)\n",
    "im = plt.imshow(esn.nodes_to_nodes[0][1]._hidden_layer_state[:, idx].T,vmin=-1, vmax=1)\n",
    "plt.xlim([0, esn.nodes_to_nodes[0][1]._hidden_layer_state.shape[0]])\n",
    "plt.ylim([0, 50])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{r}[n]$')\n",
    "plt.grid()\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=0.2)\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cb = plt.colorbar(im, cax=cax)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "fig.set_size_inches(0.5*width, height)\n",
    "plt.savefig('input_scaling_rand_train.pdf', bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "print(f_name_train[361])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of a reservoir state from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = esn.predict(X=X_test_scaled[0])\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=.15, bottom=.16, right=.99, top=.97)\n",
    "ax = plt.gca()\n",
    "rng = np.random.default_rng(12345)\n",
    "idx = rng.choice(100, 50)\n",
    "im = plt.imshow(esn.nodes_to_nodes[0][1]._hidden_layer_state[:, idx].T,vmin=-1, vmax=1)\n",
    "plt.xlim([0, esn.nodes_to_nodes[0][1]._hidden_layer_state.shape[0]])\n",
    "plt.ylim([0, 50])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{r}[n]$')\n",
    "plt.grid()\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=0.2)\n",
    "cb = plt.colorbar(im, cax=cax)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "fig.set_size_inches(0.5*width, height)\n",
    "plt.savefig('spectral_radius_rand_test.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rs in range(20):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=100, n_init=20, reassignment_ratio=0, max_no_improvement=50, init='k-means++', verbose=0, random_state=rs)\n",
    "    kmeans.fit(X=np.concatenate(X_train_scaled+X_val_scaled))\n",
    "    w_in = np.divide(kmeans.cluster_centers_, np.linalg.norm(kmeans.cluster_centers_, axis=1)[:, None])\n",
    "    print(\"Train the ESN model...\")\n",
    "    base_input_to_node = PredefinedWeightsInputToNode(predefined_input_weights=w_in.T, activation='identity', input_scaling=0.8)\n",
    "    base_node_to_node = NodeToNode(hidden_layer_size=100, spectral_radius=0.4, leakage=0.1, bias_scaling=0.0, k_rec=10, random_state=10)\n",
    "    base_reg = FastIncrementalRegression(alpha=1e-3)\n",
    "    \n",
    "    esn = ESNClassifier(input_to_node=base_input_to_node,\n",
    "                        node_to_node=base_node_to_node,\n",
    "                        regressor=base_reg)\n",
    "    \n",
    "    for X, y in zip(X_train_scaled + X_val_scaled[:-1], y_train + y_val[:-1]):\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        esn.partial_fit(X=X, y=y, classes=np.arange(10), postpone_inverse=True)\n",
    "    X = X_val[-1]\n",
    "    y = np.repeat(y_val[-1], repeats=X.shape[0], axis=0)\n",
    "    esn.partial_fit(X=X, y=y, postpone_inverse=False)\n",
    "    print(\"... done!\")\n",
    "    Y_true_train = []\n",
    "    Y_pred_train = []\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled, y_train + y_val):\n",
    "        Y_true_train.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_train.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        # mse_train.append(mean_squared_error(y, y_pred))\n",
    "    print(\"Classification training report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_train, Y_pred_train, digits=10)))\n",
    "    # print(\"MSE training: %f\\n\" % (np.mean(mse_train)))\n",
    "    \n",
    "    Y_true_test = []\n",
    "    Y_pred_test = []\n",
    "    mse_test = []\n",
    "    for X, y in zip(X_test_scaled, y_test):\n",
    "        Y_true_test.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_test.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        # mse_test.append(mean_squared_error(y, y_pred))\n",
    "    print(\"Classification test report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_test, Y_pred_test, digits=10)))\n",
    "    # print(\"MSE test: %f\\n\" % (np.mean(mse_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=100, n_init=20, reassignment_ratio=0, max_no_improvement=50, init='k-means++', verbose=2, random_state=0)\n",
    "kmeans.fit(X=np.concatenate(X_train_scaled+X_val_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_in = np.divide(kmeans.cluster_centers_, np.linalg.norm(kmeans.cluster_centers_, axis=1)[:, None])\n",
    "base_input_to_node = PredefinedWeightsInputToNode(predefined_input_weights=w_in.T, activation='identity', input_scaling=0.8)\n",
    "base_node_to_node = NodeToNode(hidden_layer_size=100, spectral_radius=0.4, leakage=0.1, bias_scaling=0.0, k_rec=10, random_state=10)\n",
    "base_reg = FastIncrementalRegression(alpha=1e-3)\n",
    "\n",
    "esn = ESNClassifier(input_to_node=base_input_to_node,\n",
    "                    node_to_node=base_node_to_node,\n",
    "                    regressor=base_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train the ESN model...\")\n",
    "with tqdm(total=len(X_train_scaled) + len(X_val_scaled)) as pbar:\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled[:-1], y_train + y_val[:-1]):\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        esn.partial_fit(X=X, y=y, classes=np.arange(10), postpone_inverse=True)\n",
    "        pbar.update(1)\n",
    "    X = X_val[-1]\n",
    "    y = np.repeat(y_val[-1], repeats=X.shape[0], axis=0)\n",
    "    esn.partial_fit(X=X, y=y, postpone_inverse=False)\n",
    "    pbar.update(1)\n",
    "print(\"... done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_true_train = []\n",
    "Y_pred_train = []\n",
    "with tqdm(total=len(X_train_scaled) + len(X_val_scaled)) as pbar:\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled, y_train + y_val):\n",
    "        Y_true_train.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_train.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        pbar.update(1)\n",
    "cm = confusion_matrix(Y_true_train, Y_pred_train)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).plot()\n",
    "print(\"Classification training report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_train, Y_pred_train, digits=10)))\n",
    "plt.show()\n",
    "\n",
    "Y_true_test = []\n",
    "Y_pred_test = []\n",
    "with tqdm(total=len(X_test_scaled)) as pbar:\n",
    "    for X, y in zip(X_test_scaled, y_test):\n",
    "        Y_true_test.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_test.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        pbar.update(1)\n",
    "cm = confusion_matrix(Y_true_test, Y_pred_test)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).plot()\n",
    "print(\"Classification test report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_test, Y_pred_test, digits=10)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of a reservoir state from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = esn.predict(X=X_train_scaled[361])\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=.15, bottom=.16, right=.99, top=.97)\n",
    "ax = plt.gca()\n",
    "rng = np.random.default_rng(12345)\n",
    "idx = rng.choice(100, 50)\n",
    "im = plt.imshow(esn.nodes_to_nodes[0][1]._hidden_layer_state[:, idx].T,vmin=-1, vmax=1)\n",
    "plt.xlim([0, esn.nodes_to_nodes[0][1]._hidden_layer_state.shape[0]])\n",
    "plt.ylim([0, len(idx)])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{r}[n]$')\n",
    "plt.grid()\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "cb = plt.colorbar(im, cax=cax)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "fig.set_size_inches(.5*width, height)\n",
    "plt.savefig('input_scaling_kmeans_train.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of a reservoir state from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = esn.predict(X=X_test_scaled[0])\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=.15, bottom=.16, right=.99, top=.97)\n",
    "ax = plt.gca()\n",
    "rng = np.random.default_rng(12345)\n",
    "idx = rng.choice(100, 50)\n",
    "im = plt.imshow(esn.nodes_to_nodes[0][1]._hidden_layer_state[:, idx].T,vmin=-1, vmax=1)\n",
    "plt.xlim([0, esn.nodes_to_nodes[0][1]._hidden_layer_state.shape[0]])\n",
    "plt.ylim([0, len(idx)])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{r}[n]$')\n",
    "plt.grid()\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "cb = plt.colorbar(im, cax=cax)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "fig.set_size_inches(.5*width, height)\n",
    "plt.savefig('leakage_kmeans_test.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.var(esn.nodes_to_nodes[0][1]._hidden_layer_state, axis=0), bins=10, orientation='horizontal')\n",
    "kmeans_states_test = esn.nodes_to_nodes[0][1]._hidden_layer_state\n",
    "plt.hist(np.var(kmeans_states_test, axis=0), orientation='horizontal')\n",
    "np.min(np.var(esn.nodes_to_nodes[0][1]._hidden_layer_state, axis=0)), np.max(np.var(esn.nodes_to_nodes[0][1]._hidden_layer_state, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.var(rand_states_test, axis=0), alpha=0.4, bins=10, color=\"black\", label='R-ESN')\n",
    "plt.hist(np.var(kmeans_states_test, axis=0), bins=10, color=\"black\", label='KM-ESN')\n",
    "plt.legend(loc='upper right')\n",
    "fig.set_size_inches(width, height)\n",
    "plt.show()\n",
    "np.var(rand_states_training, axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the reservoir size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=500, n_init=20, reassignment_ratio=0, max_no_improvement=50, init='k-means++', verbose=1, random_state=0)\n",
    "kmeans.fit(X=np.concatenate(X_train_scaled))\n",
    "# w_in = np.divide(kmeans.cluster_centers_, np.linalg.norm(kmeans.cluster_centers_, axis=1)[:, None])\n",
    "w_in = np.pad(np.divide(kmeans.cluster_centers_, np.linalg.norm(kmeans.cluster_centers_, axis=1)[:, None]), ((0, 4500), (0, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "base_input_to_node = PredefinedWeightsInputToNode(predefined_input_weights=w_in.T, activation='identity', input_scaling=0.2)\n",
    "base_node_to_node = NodeToNode(hidden_layer_size=5000, spectral_radius=0.6, leakage=0.1, bias_scaling=0.0, k_rec=10, random_state=10)\n",
    "base_reg = FastIncrementalRegression(alpha=1e-3)\n",
    "\n",
    "esn = ESNClassifier(input_to_node=base_input_to_node,\n",
    "                    node_to_node=base_node_to_node,\n",
    "                    regressor=base_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Train the ESN model...\")\n",
    "with tqdm(total=len(X_train_scaled) + len(X_val_scaled)) as pbar:\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled[:-1], y_train + y_val[:-1]):\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        esn.partial_fit(X=X, y=y, classes=np.arange(10), postpone_inverse=True)\n",
    "        pbar.update(1)\n",
    "    X = X_val[-1]\n",
    "    y = np.repeat(y_val[-1], repeats=X.shape[0], axis=0)\n",
    "    esn.partial_fit(X=X, y=y, postpone_inverse=True)\n",
    "    pbar.update(1)\n",
    "print(\"... done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true_train = []\n",
    "Y_pred_train = []\n",
    "with tqdm(total=len(X_train_scaled) + len(X_val_scaled)) as pbar:\n",
    "    for X, y in zip(X_train_scaled + X_val_scaled, y_train + y_val):\n",
    "        Y_true_train.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_train.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        pbar.update(1)\n",
    "cm = confusion_matrix(Y_true_train, Y_pred_train)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).plot()\n",
    "print(\"Classification training report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_train, Y_pred_train, digits=10)))\n",
    "plt.show()\n",
    "\n",
    "Y_true_test = []\n",
    "Y_pred_test = []\n",
    "with tqdm(total=len(X_test_scaled)) as pbar:\n",
    "    for X, y in zip(X_test_scaled, y_test):\n",
    "        Y_true_test.append(y)\n",
    "        y_pred = esn.predict_proba(X=X)\n",
    "        Y_pred_test.append(np.argmax(y_pred.sum(axis=0)))\n",
    "        y = np.repeat(y, repeats=X.shape[0], axis=0)\n",
    "        pbar.update(1)\n",
    "cm = confusion_matrix(Y_true_test, Y_pred_test)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).plot()\n",
    "print(\"Classification test report for estimator %s:\\n%s\\n\" % (esn, classification_report(Y_true_test, Y_pred_test, digits=10)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of a reservoir state from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = esn.predict(X=X_train_scaled[0], keep_reservoir_state=True)\n",
    "np.random.seed(0)\n",
    "index = np.random.choice(esn.reservoir_state.shape[1], 50, replace=False)\n",
    "plt.figure(figsize=(4, 3))\n",
    "im = plt.imshow(esn.reservoir_state[:, index].T,vmin=-1, vmax=1)\n",
    "plt.xlim([0, esn.reservoir_state.shape[0]])\n",
    "plt.ylim([0, 50])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{r}[n]$')\n",
    "plt.colorbar(im)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('reservoir_size_kmeans_train.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of a reservoir state from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = esn.predict(X=X_test_scaled[0], keep_reservoir_state=True)\n",
    "np.random.seed(0)\n",
    "index = np.random.choice(esn.reservoir_state.shape[1], 50, replace=False)\n",
    "plt.figure(figsize=(4, 3))\n",
    "im = plt.imshow(esn.reservoir_state[:, index].T,vmin=-1, vmax=1)\n",
    "plt.xlim([0, esn.reservoir_state.shape[0]])\n",
    "plt.ylim([0, 50])\n",
    "plt.xlabel(r'$n$')\n",
    "plt.ylabel(r'$\\mathbf{r}[n]$')\n",
    "plt.colorbar(im)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('reservoir_size_kmeans_test.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to fit KMeans and KMedoids for different settings (K, minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_k_means(k, mini_batch=False, X=np.ndarray):\n",
    "    print(k)\n",
    "    if mini_batch:\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, reassignment_ratio=0, max_no_improvement=50, init='k-means++', verbose=0)\n",
    "    else:\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, reassignment_ratio=0, max_no_improvement=50, init='k-means++', verbose=0)\n",
    "    kmeans.fit(X=np.vstack(X_train_scaled))\n",
    "    return kmeans.inertia_\n",
    "\n",
    "def fit_k_medoids(k):\n",
    "    kmedoids = KMedoids(n_clusters=k, metric='euclidean',init='k-medoids++', max_iter=300, random_state=0)\n",
    "    kmedoids.fit(X=np.vstack(X_train_scaled))\n",
    "    return kmedoids.inertia_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweep along various $K$ and compare $K$-means, Mini-batch $K$-means and $K$-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inertias_k_means = Parallel(n_jobs=-1, verbose=50)(delayed(fit_k_means)(k, True) for k in [1460])\n",
    "# silhouette_scores_k_means = [None] * len(range(2, 1001))\n",
    "# for k in range(2, 10):\n",
    "#     print(k)\n",
    "#     silhouette_scores_k_means[k-2] = fit_k_means(k, True, X_train_scaled)\n",
    "# inertias_k_medoids = Parallel(n_jobs=-1, verbose=50)(delayed(fit_k_medoids)(k) for k in range(10, 501, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(X=inertias_k_means, fname=\"inertias_minibatch_k_means.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "# plt.plot(range(10, 1001, 10), inertias_k_means, label=r\"$K$-Means\")\n",
    "plt.plot(range(10, 100, 10), silhouette_scores_k_means, label=r\"Mini-batch-$K$-Means\")\n",
    "# plt.plot(range(10, 501, 10), inertias_k_medoids, label=\"$K-\\text{Medoids}$\")\n",
    "plt.xlabel(r'$K$')\n",
    "plt.ylabel(r'Silhouette score')\n",
    "plt.xlim([10, 100])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"silhouette_score.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
