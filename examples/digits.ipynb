{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing hand-written digits\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook adapts the existing example of applying support vector classification from scikit-learn ([https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py)) to PyRCN to demonstrate, how PyRCN can be used to classify hand-written digits.\n",
    "\n",
    "The tutorial is based on numpy, scikit-learn and PyRCN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import (\n",
    "    ParameterGrid, RandomizedSearchCV, cross_validate)\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from pyrcn.model_selection import SequentialSearchCV\n",
    "from pyrcn.echo_state_network import ESNClassifier\n",
    "from pyrcn.metrics import accuracy_score\n",
    "from pyrcn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "The dataset is already part of scikit-learn and consists of 1797 8x8 images. \n",
    "\n",
    "We are using our dataloader that is derived from scikit-learns dataloader and returns arrays of 8x8 sequences and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True, as_sequence=True)\n",
    "print(\"Number of digits: {0}\".format(len(X)))\n",
    "print(\"Shape of digits {0}\".format(X[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset in training and test\n",
    "\n",
    "Afterwards, we split the dataset into training and test sets. We train the ESN using 80% of the digits and test it using the remaining images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratify = np.asarray([np.unique(yt) for yt in y]).flatten()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=stratify, random_state=42)\n",
    "X_tr = np.copy(X_train)\n",
    "y_tr = np.copy(y_train)\n",
    "X_te = np.copy(X_test)\n",
    "y_te = np.copy(y_test)\n",
    "for k, _ in enumerate(y_tr):\n",
    "    y_tr[k] = np.repeat(y_tr[k], 8, 0)\n",
    "for k, _ in enumerate(y_te):\n",
    "    y_te[k] = np.repeat(y_te[k], 8, 0)\n",
    "\n",
    "print(\"Number of digits in training set: {0}\".format(len(X_train)))\n",
    "print(\"Shape of digits in training set: {0}\".format(X_train[0].shape))\n",
    "print(\"Number of digits in test set: {0}\".format(len(X_test)))\n",
    "print(\"Shape of digits in test set: {0}\".format(X_test[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a ESN\n",
    "\n",
    "To develop an ESN model for digit recognition, we need to tune several hyper-parameters, e.g., input_scaling, spectral_radius, bias_scaling and leaky integration.\n",
    "\n",
    "We follow the way proposed in the introductory paper of PyRCN to optimize hyper-parameters sequentially.\n",
    "\n",
    "We define the search spaces for each step together with the type of search (a grid search in this context).\n",
    "\n",
    "At last, we initialize a SeqToLabelESNClassifier with the desired output strategy and with the initially fixed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initially_fixed_params = {'hidden_layer_size': 50,\n",
    "                          'input_activation': 'identity',\n",
    "                          'k_in': 5,\n",
    "                          'bias_scaling': 0.0,\n",
    "                          'reservoir_activation': 'tanh',\n",
    "                          'leakage': 1.0,\n",
    "                          'bidirectional': False,\n",
    "                          'k_rec': 10,\n",
    "                          'wash_out': 0,\n",
    "                          'continuation': False,\n",
    "                          'alpha': 1e-5,\n",
    "                          'random_state': 42,\n",
    "                          'decision_strategy': \"winner_takes_all\"}\n",
    "\n",
    "step1_esn_params = {'input_scaling': uniform(loc=1e-2, scale=1),\n",
    "                    'spectral_radius': uniform(loc=0, scale=2)}\n",
    "\n",
    "step2_esn_params = {'leakage': loguniform(1e-5, 1e0)}\n",
    "step3_esn_params = {'bias_scaling': uniform(loc=0, scale=2)}\n",
    "step4_esn_params = {'alpha': loguniform(1e-5, 1e0)}\n",
    "\n",
    "kwargs_step1 = {'n_iter': 200, 'random_state': 42, 'verbose': 1, 'n_jobs': -1,\n",
    "                'scoring': make_scorer(accuracy_score)\n",
    "                }\n",
    "kwargs_step2 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1,\n",
    "                'scoring': make_scorer(accuracy_score)\n",
    "                }\n",
    "kwargs_step3 = {'verbose': 1, 'n_jobs': -1,\n",
    "                'scoring': make_scorer(accuracy_score)\n",
    "                }\n",
    "kwargs_step4 = {'n_iter': 50, 'random_state': 42, 'verbose': 1, 'n_jobs': -1,\n",
    "                'scoring': make_scorer(accuracy_score)\n",
    "                }\n",
    "\n",
    "# The searches are defined similarly to the steps of a sklearn.pipeline.Pipeline:\n",
    "searches = [('step1', RandomizedSearchCV, step1_esn_params, kwargs_step1),\n",
    "            ('step2', RandomizedSearchCV, step2_esn_params, kwargs_step2),\n",
    "            ('step3', RandomizedSearchCV, step3_esn_params, kwargs_step3),\n",
    "            ('step4', RandomizedSearchCV, step4_esn_params, kwargs_step4)]\n",
    "\n",
    "base_esn = ESNClassifier(**initially_fixed_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "We provide a SequentialSearchCV that basically iterates through the list of searches that we have defined before. It can be combined with any model selection tool from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequential_search = SequentialSearchCV(base_esn,\n",
    "                                       searches=searches).fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the ESN with final hyper-parameters\n",
    "\n",
    "After the optimization, we extract the ESN with final hyper-parameters as the result of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_esn = sequential_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_esn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_search.all_cv_results_[\"step4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the ESN\n",
    "\n",
    "Finally, we increase the reservoir size and compare the impact of uni- and bidirectional ESNs. Notice that the ESN strongly benefit from both, increasing the reservoir size and from the bi-directional working mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_size': [50, 100, 200, 400, 500],\n",
    "              'bidirectional': [False, True]}\n",
    "\n",
    "print(\"CV results\\tFit time\\tInference time\\tAccuracy score\\tSize[Bytes]\")\n",
    "for params in ParameterGrid(param_grid):\n",
    "    esn_cv = cross_validate(clone(base_esn).set_params(**params), X=X_train, y=y_train,\n",
    "                            scoring=make_scorer(accuracy_score), n_jobs=-1)\n",
    "    t1 = time.time()\n",
    "    esn = clone(base_esn).set_params(**params).fit(X_train, y_train)\n",
    "    t_fit = time.time() - t1\n",
    "    t1 = time.time()\n",
    "    esn_par = clone(base_esn).set_params(**params).fit(X_train, y_train, n_jobs=-1)\n",
    "    t_fit_par = time.time() - t1\n",
    "    mem_size = esn.__sizeof__()\n",
    "    t1 = time.time()\n",
    "    acc_score = accuracy_score(y_test, esn.predict(X_test))\n",
    "    t_inference = time.time() - t1\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\".format(esn_cv, t_fit, t_inference, acc_score,\n",
    "                                           mem_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
